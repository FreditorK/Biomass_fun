{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "366cc677",
   "metadata": {},
   "source": [
    "# Ecosystem Services Valuation Workflow\n",
    "\n",
    "This notebook follows the 11-phase roadmap from the project README. Fill in each section sequentially to maintain provenance and reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adc418d",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "- Activate the `biomass` environment (`conda activate biomass`).\n",
    "- Update the project path, AOI coordinates, and CDSE credentials in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "415cf286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "from rasterio.warp import calculate_default_transform, reproject\n",
    "from rasterio.io import MemoryFile\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "print(\"Core libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13720d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: /Users/lmm122/Documents/github/Biomass_fun/data\n",
      "Found 2 SAFE folders inside data/:\n",
      " • S2C_MSIL2A_20251113T024511_N0511_R089_T50RQV_20251113T054013.SAFE\n",
      " • S2C_MSIL2A_20251113T024511_N0511_R089_T51RTQ_20251113T054013.SAFE\n",
      "Ancillary data directory: /Users/lmm122/Documents/github/Biomass_fun/data/ancillary\n",
      "AOI file detected: /Users/lmm122/Documents/github/Biomass_fun/data/aoi.geojson\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "\n",
    "SAFE_PATTERN = \"S2C_MSIL2A_*.SAFE\"\n",
    "SAFE_ROOTS = sorted(DATA_DIR.glob(SAFE_PATTERN))\n",
    "if not SAFE_ROOTS:\n",
    "    raise FileNotFoundError(\n",
    "        f\"No Sentinel-2 SAFE directories found via pattern '{SAFE_PATTERN}' in {DATA_DIR}\"\n",
    "    )\n",
    "print(f\"Found {len(SAFE_ROOTS)} SAFE folders inside data/:\")\n",
    "for safe in SAFE_ROOTS:\n",
    "    print(\" •\", safe.name)\n",
    "\n",
    "ANCILLARY_DIR = DATA_DIR / \"ancillary\"\n",
    "ANCILLARY_DIR.mkdir(exist_ok=True)\n",
    "print(f\"Ancillary data directory: {ANCILLARY_DIR}\")\n",
    "\n",
    "AOI_PATH = DATA_DIR / \"aoi.geojson\"\n",
    "if AOI_PATH.exists():\n",
    "    print(f\"AOI file detected: {AOI_PATH}\")\n",
    "else:\n",
    "    print(f\"AOI file not found (expected at {AOI_PATH}). Drop a GeoJSON/shapefile copy there when ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5769710b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vector data from /Users/lmm122/Documents/github/Biomass_fun/data/aoi.geojson (1 features, CRS=EPSG:4326)\n",
      "AOI centroid: (31.1209, 119.8241)\n"
     ]
    }
   ],
   "source": [
    "def load_optional_vector(path: Path) -> Optional[gpd.GeoDataFrame]:\n",
    "    if not path.exists():\n",
    "        return None\n",
    "    gdf = gpd.read_file(path)\n",
    "    print(f\"Loaded vector data from {path} ({len(gdf)} features, CRS={gdf.crs})\")\n",
    "    return gdf.to_crs(\"EPSG:4326\") if gdf.crs else gdf\n",
    "\n",
    "AOI_GDF = load_optional_vector(AOI_PATH)\n",
    "if AOI_GDF is None:\n",
    "    print(\"AOI_GDF not loaded yet. Provide a GeoJSON/GeoPackage/Shapefile in data/.\")\n",
    "else:\n",
    "    # Reproject to a projected CRS (UTM zone 50N for this region) for accurate centroid calculation\n",
    "    aoi_projected = AOI_GDF.to_crs(\"EPSG:32650\")  # UTM Zone 50N\n",
    "    centroid_projected = aoi_projected.geometry.centroid.union_all()\n",
    "    # Convert back to WGS84 for display\n",
    "    AOI_CENTROID = gpd.GeoSeries([centroid_projected], crs=\"EPSG:32650\").to_crs(\"EPSG:4326\")[0]\n",
    "    print(f\"AOI centroid: ({AOI_CENTROID.y:.4f}, {AOI_CENTROID.x:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "530491df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[missing] /Users/lmm122/Documents/github/Biomass_fun/data/ancillary/dem.tif\n",
      "[missing] /Users/lmm122/Documents/github/Biomass_fun/data/ancillary/slope.tif\n",
      "[missing] /Users/lmm122/Documents/github/Biomass_fun/data/ancillary/precipitation_mm_per_year.tif\n"
     ]
    }
   ],
   "source": [
    "ANCILLARY_RASTERS = {\n",
    "    \"dem\": ANCILLARY_DIR / \"dem.tif\",\n",
    "    \"slope\": ANCILLARY_DIR / \"slope.tif\",\n",
    "    \"precip\": ANCILLARY_DIR / \"precipitation_mm_per_year.tif\",\n",
    "}\n",
    "\n",
    "\n",
    "def inspect_raster(path: Path):\n",
    "    if not path.exists():\n",
    "        print(f\"[missing] {path}\")\n",
    "        return None\n",
    "    with rasterio.open(path) as ds:\n",
    "        print(\n",
    "            f\"[loaded] {path.name}: {ds.width}x{ds.height} px, res={ds.res}, crs={ds.crs}, nodata={ds.nodata}\"\n",
    "        )\n",
    "        return ds.profile\n",
    "\n",
    "ANCILLARY_PROFILES = {name: inspect_raster(path) for name, path in ANCILLARY_RASTERS.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cc6263",
   "metadata": {},
   "source": [
    "## Phase 0: CDSE API & Download\n",
    "- Implement a reusable CDSE authentication helper (env vars or config file).\n",
    "- Load AOI centroid coordinates and build a 25 km buffer polygon (`geopandas`/`shapely`).\n",
    "- Use the CDSE search endpoint to query Sentinel-2 L2A products intersecting the AOI.\n",
    "- Filter candidates by acquisition date, cloud cover, and processing baseline.\n",
    "- Log the chosen product(s) with metadata (UUID, title, footprint, cloud %, download URL).\n",
    "- Download the `.SAFE` archives into `DATA_DIR` and verify checksums if provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f01f6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>safe_name</th>\n",
       "      <th>acquisition_utc</th>\n",
       "      <th>processing_baseline</th>\n",
       "      <th>relative_orbit</th>\n",
       "      <th>tile</th>\n",
       "      <th>local_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S2C_MSIL2A_20251113T024511_N0511_R089_T50RQV_2...</td>\n",
       "      <td>2025-11-13 02:45:11</td>\n",
       "      <td>N0511</td>\n",
       "      <td>R089</td>\n",
       "      <td>T50RQV</td>\n",
       "      <td>/Users/lmm122/Documents/github/Biomass_fun/dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S2C_MSIL2A_20251113T024511_N0511_R089_T51RTQ_2...</td>\n",
       "      <td>2025-11-13 02:45:11</td>\n",
       "      <td>N0511</td>\n",
       "      <td>R089</td>\n",
       "      <td>T51RTQ</td>\n",
       "      <td>/Users/lmm122/Documents/github/Biomass_fun/dat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           safe_name     acquisition_utc  \\\n",
       "0  S2C_MSIL2A_20251113T024511_N0511_R089_T50RQV_2... 2025-11-13 02:45:11   \n",
       "1  S2C_MSIL2A_20251113T024511_N0511_R089_T51RTQ_2... 2025-11-13 02:45:11   \n",
       "\n",
       "  processing_baseline relative_orbit    tile  \\\n",
       "0               N0511           R089  T50RQV   \n",
       "1               N0511           R089  T51RTQ   \n",
       "\n",
       "                                          local_path  \n",
       "0  /Users/lmm122/Documents/github/Biomass_fun/dat...  \n",
       "1  /Users/lmm122/Documents/github/Biomass_fun/dat...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    SAFE_ROOTS\n",
    "except NameError as exc:\n",
    "    raise RuntimeError(\"SAFE_ROOTS not initialized. Run the setup cell above first.\") from exc\n",
    "\n",
    "\n",
    "def summarize_safe(path: Path) -> dict:\n",
    "    tokens = path.name.split(\"_\")\n",
    "    return {\n",
    "        \"safe_name\": path.name,\n",
    "        \"acquisition_utc\": pd.to_datetime(tokens[2], format=\"%Y%m%dT%H%M%S\"),\n",
    "        \"processing_baseline\": tokens[3],\n",
    "        \"relative_orbit\": tokens[4],\n",
    "        \"tile\": tokens[5],\n",
    "        \"local_path\": path.resolve().as_posix(),\n",
    "    }\n",
    "\n",
    "product_log = pd.DataFrame([summarize_safe(p) for p in SAFE_ROOTS])\n",
    "product_log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936b79c1",
   "metadata": {},
   "source": [
    "## Phase 1: Data Loading & Preprocessing\n",
    "- Parse the `.SAFE` structure to locate band JP2 paths (10 m & 20 m resolutions).\n",
    "- Load B2, B3, B4, B8, B11, B12 arrays; resample 20 m bands to the 10 m reference grid.\n",
    "- Apply the scaling factor (÷10,000) and cast to `float32` reflectance.\n",
    "- Generate nodata masks (<=0) and cloud masks using `MSK_CLDPRB_20m` or SCL rasters.\n",
    "- Combine masks into a single `valid` mask to keep clean pixels for downstream phases.\n",
    "- Build quick-look products: RGB, SWIR composites, cloud overlays for QA/QC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2789c42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "from contextlib import ExitStack\n",
    "from rasterio.merge import merge\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "BAND_SPECS = {\n",
    "    \"B02\": {\"label\": \"blue\", \"folder\": \"R10m\", \"suffix\": \"10m\"},\n",
    "    \"B03\": {\"label\": \"green\", \"folder\": \"R10m\", \"suffix\": \"10m\"},\n",
    "    \"B04\": {\"label\": \"red\", \"folder\": \"R10m\", \"suffix\": \"10m\"},\n",
    "    \"B08\": {\"label\": \"nir\", \"folder\": \"R10m\", \"suffix\": \"10m\"},\n",
    "    \"B11\": {\"label\": \"swir1\", \"folder\": \"R20m\", \"suffix\": \"20m\"},\n",
    "    \"B12\": {\"label\": \"swir2\", \"folder\": \"R20m\", \"suffix\": \"20m\"},\n",
    "}\n",
    "\n",
    "SCALING_FACTOR = 10000.0\n",
    "PIXEL_AREA_HA_10M = 0.01\n",
    "\n",
    "def get_granule_dir(safe_dir: Path) -> Path:\n",
    "    granules = sorted((safe_dir / \"GRANULE\").iterdir())\n",
    "    if not granules:\n",
    "        raise FileNotFoundError(f\"No GRANULE directory found in {safe_dir}\")\n",
    "    return granules[0]\n",
    "\n",
    "\n",
    "def find_band_path(safe_dir: Path, band_id: str) -> Path:\n",
    "    \"\"\"Find a band file inside a Sentinel-2 SAFE folder, searching IMG_DATA recursively.\"\"\"\n",
    "    spec = BAND_SPECS[band_id]\n",
    "    granule = get_granule_dir(safe_dir)\n",
    "\n",
    "    # Look under GRANULE/IMG_DATA, any subfolder (R10m, R20m, R60m, etc.)\n",
    "    search_root = granule / \"IMG_DATA\"\n",
    "    suffix = spec[\"suffix\"]  # \"10m\" or \"20m\"\n",
    "    pattern = f\"*_{band_id}_{suffix}.jp2\"\n",
    "\n",
    "    matches = sorted(search_root.rglob(pattern))\n",
    "    if not matches:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Band {band_id} not found in {safe_dir}\\n\"\n",
    "            f\"Looked under {search_root} with pattern '{pattern}'\"\n",
    "        )\n",
    "\n",
    "    print(f\"{band_id}: using {matches[0].relative_to(safe_dir)}\")\n",
    "    return matches[0]\n",
    "\n",
    "def find_quality_mask(safe_dir: Path, filename: str) -> Path:\n",
    "    granule = get_granule_dir(safe_dir)\n",
    "    candidate = granule / \"QI_DATA\" / filename\n",
    "    if not candidate.exists():\n",
    "        raise FileNotFoundError(f\"Quality mask {filename} missing in {safe_dir}\")\n",
    "    return candidate\n",
    "\n",
    "def merge_datasets(paths, dst_profile=None, resampling=Resampling.bilinear):\n",
    "    with ExitStack() as stack:\n",
    "        datasets = [stack.enter_context(rasterio.open(p)) for p in paths]\n",
    "        if dst_profile is not None and \"crs\" in dst_profile:\n",
    "            dst_crs = dst_profile[\"crs\"]\n",
    "        else:\n",
    "            dst_crs = datasets[0].crs\n",
    "\n",
    "        reproj_datasets = []\n",
    "        memfiles = []\n",
    "        for src in datasets:\n",
    "            if src.crs == dst_crs:\n",
    "                # no reprojection needed\n",
    "                reproj_datasets.append(src)\n",
    "                continue\n",
    "            transform, width, height = calculate_default_transform(src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
    "            profile = src.profile.copy()\n",
    "            profile.update(crs=dst_crs, transform=transform, width=width, height=height)\n",
    "            \n",
    "            memfile = MemoryFile()\n",
    "            memfiles.append(memfile)\n",
    "            dst = memfile.open(**profile)\n",
    "            stack.enter_context(dst)\n",
    "\n",
    "            for i in range(1, src.count + 1):\n",
    "                reproject(source=rasterio.band(src, i),\n",
    "                          destination=rasterio.band(dst, i),\n",
    "                          src_transform=src.transform,\n",
    "                          src_crs=src.crs,\n",
    "                          dst_crs=dst_crs,\n",
    "                          resampling=resampling)\n",
    "                reproj_datasets.append(dst)\n",
    "\n",
    "        merge_kwargs = {}\n",
    "        if dst_profile is not None:\n",
    "            merge_kwargs.update(transform=dst_profile[\"transform\"],\n",
    "                                crs=dst_crs,\n",
    "                                width=dst_profile[\"width\"],\n",
    "                                height=dst_profile[\"height\"]\n",
    "                                )\n",
    "            \n",
    "        mosaic, out_transform = merge(reproj_datasets, resampling=resampling, dst_kwds=merge_kwargs)\n",
    "        base_profile = reproj_datasets[0].profile.copy()\n",
    "        base_profile.update(height=mosaic.shape[1], \n",
    "                            width=mosaic.shape[2],\n",
    "                            transform=out_transform,\n",
    "                            crs=dst_crs,\n",
    "                            count=mosaic.shape[0],\n",
    "                            nodata=0,\n",
    "                            dtype=mosaic.dtype)\n",
    "        \n",
    "        return mosaic[0], base_profile\n",
    "\n",
    "def load_band(band_id: str, dst_profile=None, resampling=Resampling.bilinear):\n",
    "    paths = [find_band_path(safe, band_id) for safe in SAFE_ROOTS]\n",
    "    return merge_datasets(paths, dst_profile=dst_profile, resampling=resampling)\n",
    "\n",
    "\n",
    "def to_reflectance(array: np.ndarray) -> np.ndarray:\n",
    "    return (array.astype(np.float32) / SCALING_FACTOR).clip(0, 1.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8b0c507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B04: using GRANULE/L2A_T50RQV_A006208_20251113T024512/IMG_DATA/R10m/T50RQV_20251113T024511_B04_10m.jp2\n",
      "B04: using GRANULE/L2A_T51RTQ_A006208_20251113T024512/IMG_DATA/R10m/T51RTQ_20251113T024511_B04_10m.jp2\n"
     ]
    },
    {
     "ename": "RasterioError",
     "evalue": "CRS mismatch with source: <open DatasetReader name='/Users/lmm122/Documents/github/Biomass_fun/data/S2C_MSIL2A_20251113T024511_N0511_R089_T51RTQ_20251113T054013.SAFE/GRANULE/L2A_T51RTQ_A006208_20251113T024512/IMG_DATA/R10m/T51RTQ_20251113T024511_B04_10m.jp2' mode='r'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRasterioError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m reference_red, reference_profile = \u001b[43mload_band\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mB04\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m REFERENCE_PROFILE = {\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m: reference_profile[\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcrs\u001b[39m\u001b[33m\"\u001b[39m: reference_profile[\u001b[33m\"\u001b[39m\u001b[33mcrs\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mwidth\u001b[39m\u001b[33m\"\u001b[39m: reference_profile[\u001b[33m\"\u001b[39m\u001b[33mwidth\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mheight\u001b[39m\u001b[33m\"\u001b[39m: reference_profile[\u001b[33m\"\u001b[39m\u001b[33mheight\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      7\u001b[39m }\n\u001b[32m      9\u001b[39m BAND_DATA: Dict[\u001b[38;5;28mstr\u001b[39m, np.ndarray] = {\u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m: to_reflectance(reference_red)}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 109\u001b[39m, in \u001b[36mload_band\u001b[39m\u001b[34m(band_id, dst_profile, resampling)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_band\u001b[39m(band_id: \u001b[38;5;28mstr\u001b[39m, dst_profile=\u001b[38;5;28;01mNone\u001b[39;00m, resampling=Resampling.bilinear):\n\u001b[32m    108\u001b[39m     paths = [find_band_path(safe, band_id) \u001b[38;5;28;01mfor\u001b[39;00m safe \u001b[38;5;129;01min\u001b[39;00m SAFE_ROOTS]\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_profile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdst_profile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresampling\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresampling\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 95\u001b[39m, in \u001b[36mmerge_datasets\u001b[39m\u001b[34m(paths, dst_profile, resampling)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dst_profile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     89\u001b[39m     merge_kwargs.update(transform=dst_profile[\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     90\u001b[39m                         crs=dst_crs,\n\u001b[32m     91\u001b[39m                         width=dst_profile[\u001b[33m\"\u001b[39m\u001b[33mwidth\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     92\u001b[39m                         height=dst_profile[\u001b[33m\"\u001b[39m\u001b[33mheight\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     93\u001b[39m                         )\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m mosaic, out_transform = \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreproj_datasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresampling\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresampling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_kwds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerge_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m base_profile = reproj_datasets[\u001b[32m0\u001b[39m].profile.copy()\n\u001b[32m     97\u001b[39m base_profile.update(height=mosaic.shape[\u001b[32m1\u001b[39m], \n\u001b[32m     98\u001b[39m                     width=mosaic.shape[\u001b[32m2\u001b[39m],\n\u001b[32m     99\u001b[39m                     transform=out_transform,\n\u001b[32m   (...)\u001b[39m\u001b[32m    102\u001b[39m                     nodata=\u001b[32m0\u001b[39m,\n\u001b[32m    103\u001b[39m                     dtype=mosaic.dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/biomass/lib/python3.11/site-packages/rasterio/merge.py:458\u001b[39m, in \u001b[36mmerge\u001b[39m\u001b[34m(sources, bounds, res, nodata, dtype, precision, indexes, output_count, resampling, method, target_aligned_pixels, mem_limit, use_highest_res, masked, dst_path, dst_kwds)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dataset_opener(dataset) \u001b[38;5;28;01mas\u001b[39;00m src:\n\u001b[32m    455\u001b[39m \n\u001b[32m    456\u001b[39m     \u001b[38;5;66;03m# Intersect source bounds and tile bounds\u001b[39;00m\n\u001b[32m    457\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m first_crs != src.crs:\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m RasterioError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCRS mismatch with source: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    460\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    461\u001b[39m         ibounds = _intersect_bounds(\n\u001b[32m    462\u001b[39m             src.bounds, chunk_bounds, chunk_transform\n\u001b[32m    463\u001b[39m         )\n",
      "\u001b[31mRasterioError\u001b[39m: CRS mismatch with source: <open DatasetReader name='/Users/lmm122/Documents/github/Biomass_fun/data/S2C_MSIL2A_20251113T024511_N0511_R089_T51RTQ_20251113T054013.SAFE/GRANULE/L2A_T51RTQ_A006208_20251113T024512/IMG_DATA/R10m/T51RTQ_20251113T024511_B04_10m.jp2' mode='r'>"
     ]
    }
   ],
   "source": [
    "reference_red, reference_profile = load_band(\"B04\")\n",
    "REFERENCE_PROFILE = {\n",
    "    \"transform\": reference_profile[\"transform\"],\n",
    "    \"crs\": reference_profile[\"crs\"],\n",
    "    \"width\": reference_profile[\"width\"],\n",
    "    \"height\": reference_profile[\"height\"],\n",
    "}\n",
    "\n",
    "BAND_DATA: Dict[str, np.ndarray] = {\"red\": to_reflectance(reference_red)}\n",
    "for band_id, spec in BAND_SPECS.items():\n",
    "    if spec[\"label\"] == \"red\":\n",
    "        continue\n",
    "    arr, _ = load_band(band_id, dst_profile=reference_profile)\n",
    "    BAND_DATA[spec[\"label\"]] = to_reflectance(arr)\n",
    "\n",
    "cloud_probability_paths = [find_quality_mask(safe, \"MSK_CLDPRB_20m.jp2\") for safe in SAFE_ROOTS]\n",
    "cloud_prob_raw, _ = merge_datasets(\n",
    "    cloud_probability_paths,\n",
    "    dst_profile=reference_profile,\n",
    "    resampling=Resampling.bilinear,\n",
    ")\n",
    "cloud_probability = cloud_prob_raw.astype(np.float32)\n",
    "\n",
    "scl_paths = [find_quality_mask(safe, \"MSK_CLASSI_B00.jp2\") for safe in SAFE_ROOTS]\n",
    "scl_raw, _ = merge_datasets(\n",
    "    scl_paths,\n",
    "    dst_profile=reference_profile,\n",
    "    resampling=Resampling.nearest,\n",
    ")\n",
    "SCL = scl_raw.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648897d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m BAND_DATA = BAND_DATA_COPY.copy()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m stack_for_mask = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mBAND_DATA\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m nodata_mask = np.any(stack_for_mask <= \u001b[32m0.0\u001b[39m, axis=\u001b[32m0\u001b[39m)\n\u001b[32m      5\u001b[39m cloud_mask = cloud_probability >= \u001b[32m40\u001b[39m  \u001b[38;5;66;03m# % probability threshold\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/biomass/lib/python3.11/site-packages/numpy/_core/shape_base.py:460\u001b[39m, in \u001b[36mstack\u001b[39m\u001b[34m(arrays, axis, out, dtype, casting)\u001b[39m\n\u001b[32m    458\u001b[39m shapes = {arr.shape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays}\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shapes) != \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mall input arrays must have the same shape\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    462\u001b[39m result_ndim = arrays[\u001b[32m0\u001b[39m].ndim + \u001b[32m1\u001b[39m\n\u001b[32m    463\u001b[39m axis = normalize_axis_index(axis, result_ndim)\n",
      "\u001b[31mValueError\u001b[39m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "stack_for_mask = np.stack(list(BAND_DATA.values()), axis=0)\n",
    "nodata_mask = np.any(stack_for_mask <= 0.0, axis=0)\n",
    "cloud_mask = cloud_probability >= 40  # % probability threshold\n",
    "scl_cloud = np.isin(SCL, [3, 8, 9, 10, 11])\n",
    "valid_mask = ~(nodata_mask | cloud_mask | scl_cloud)\n",
    "\n",
    "MASKS = {\n",
    "    \"nodata\": nodata_mask,\n",
    "    \"cloud_prob\": cloud_mask,\n",
    "    \"scl_cloud\": scl_cloud,\n",
    "    \"valid\": valid_mask,\n",
    "    \"cloud_probability\": cloud_probability,\n",
    "    \"scl\": SCL,\n",
    "}\n",
    "\n",
    "print(\n",
    "    \"Loaded bands:\", \", \".join(sorted(BAND_DATA.keys())),\n",
    "    \"| valid pixels:\", int(valid_mask.sum()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b53dce0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_align_raster(path: Path, reference_profile: dict | None = None):\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(path)\n",
    "    with rasterio.open(path) as src:\n",
    "        data = src.read(1)\n",
    "        profile = src.profile\n",
    "        if reference_profile is None:\n",
    "            return data, profile\n",
    "        reprojected, new_profile = merge_datasets([path], dst_profile=reference_profile, resampling=Resampling.bilinear)\n",
    "        return reprojected, new_profile\n",
    "\n",
    "\n",
    "def clip_raster_to_aoi(array: np.ndarray, profile: dict, aoi_gdf: gpd.GeoDataFrame):\n",
    "    if aoi_gdf is None or aoi_gdf.empty:\n",
    "        return array, profile\n",
    "    geoms = [geom.__geo_interface__ for geom in aoi_gdf.to_crs(profile[\"crs\"]).geometry]\n",
    "    with rasterio.Env():\n",
    "        with MemoryFile() as memfile:\n",
    "            with memfile.open(**profile) as dataset:\n",
    "                dataset.write(array, 1)\n",
    "                clipped, clipped_transform = mask(dataset, geoms, crop=True)\n",
    "    new_profile = profile.copy()\n",
    "    new_profile.update(\n",
    "        height=clipped.shape[1],\n",
    "        width=clipped.shape[2],\n",
    "        transform=clipped_transform,\n",
    "    )\n",
    "    return clipped[0], new_profile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c67174d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No ancillary rasters have been aligned yet.\n"
     ]
    }
   ],
   "source": [
    "ancillary_arrays = {}\n",
    "for name, path in ANCILLARY_RASTERS.items():\n",
    "    if not path.exists():\n",
    "        continue\n",
    "    arr, profile = load_and_align_raster(path, reference_profile=reference_profile)\n",
    "    if AOI_GDF is not None:\n",
    "        arr, profile = clip_raster_to_aoi(arr, profile, AOI_GDF)\n",
    "    ancillary_arrays[name] = {\"array\": arr, \"profile\": profile}\n",
    "    print(f\"Aligned ancillary raster '{name}' -> shape {arr.shape}\")\n",
    "\n",
    "if not ancillary_arrays:\n",
    "    print(\"No ancillary rasters have been aligned yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f2f8281",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MASKS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m blue  = BAND_DATA[\u001b[33m\"\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Task 1.4: apply your combined validity mask\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m valid = \u001b[43mMASKS\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mvalid\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Set invalid pixels to 0 (black) for visualization\u001b[39;00m\n\u001b[32m     12\u001b[39m rgb = np.stack([red, green, blue], axis=-\u001b[32m1\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'MASKS' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Minimal Phase 1 code using what you already defined ---\n",
    "\n",
    "# Task 1.2 & 1.3 are already done: BAND_DATA has reflectances (0–1.x)\n",
    "red   = BAND_DATA[\"red\"]\n",
    "green = BAND_DATA[\"green\"]\n",
    "blue  = BAND_DATA[\"blue\"]\n",
    "\n",
    "# Task 1.4: apply your combined validity mask\n",
    "valid = MASKS[\"valid\"]\n",
    "\n",
    "# Set invalid pixels to 0 (black) for visualization\n",
    "rgb = np.stack([red, green, blue], axis=-1)\n",
    "rgb[~valid] = 0\n",
    "\n",
    "# Optionally rescale to 0–1 for nicer display (simple contrast stretch)\n",
    "p99 = np.nanpercentile(rgb[valid], 99)\n",
    "rgb_disp = np.clip(rgb / p99, 0, 1)\n",
    "\n",
    "# Task 1.5: visualize true-color composite\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(rgb_disp)\n",
    "plt.title(\"Sentinel-2 True-Color Composite (B04, B03, B02)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d3ce20",
   "metadata": {},
   "source": [
    "## Phase 2: Vegetation Indices\n",
    "- Implement NDVI, EVI, and optional SAVI with epsilon protection on denominators.\n",
    "- Clip outputs to the [-1, 1] range and set invalid pixels to `NaN` using `MASKS`.\n",
    "- Summarize each index with descriptive stats (min, max, mean, median, std, percentiles).\n",
    "- Plot map panels and histograms to confirm distributions and detect anomalies.\n",
    "- Flag out-of-range values before feeding indices into classification or biomass models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabe632d",
   "metadata": {},
   "source": [
    "## Phase 3: Land Cover Classification\n",
    "- Define NDVI-based thresholds for `non-forest`, `sparse`, `moderate`, and `dense` classes.\n",
    "- Create a categorical raster using the thresholds and `MASKS[\"valid\"]`.\n",
    "- Calculate area (ha) per class using pixel area conversions.\n",
    "- Plot a classification map with an intuitive color palette.\n",
    "- Summarize counts/areas in a table for reporting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537f6e4c",
   "metadata": {},
   "source": [
    "## Phase 4: Biomass Estimation\n",
    "- Select or cite an allometric equation suitable for the study region.\n",
    "- Apply the equation pixel-wise to generate a biomass raster (tons/ha).\n",
    "- Mask low-vegetation pixels (e.g., NDVI < 0.2) before aggregating.\n",
    "- Enforce realistic min/max biomass bounds to avoid outliers.\n",
    "- Compute total biomass (tons) using pixel area (0.01 ha at 10 m).\n",
    "- Visualize biomass distribution with a legend and summary statistics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5228a6e",
   "metadata": {},
   "source": [
    "## Phase 5: Analysis & Validation\n",
    "- Derive descriptive stats (mean, median, std, min, max) for biomass and key indices.\n",
    "- Build histograms/boxplots to inspect distributions and potential skew.\n",
    "- Compare aggregated values to literature benchmarks for similar ecosystems.\n",
    "- Conduct sensitivity checks on main parameters (e.g., NDVI thresholds, coefficients).\n",
    "- Document assumptions, uncertainties, and data quality caveats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d04793",
   "metadata": {},
   "source": [
    "## Phase 6: Water Detection\n",
    "- Compute NDWI and MNDWI using the reflectance bands already loaded.\n",
    "- Apply tuned thresholds to delineate water bodies.\n",
    "- Separate water classes by permanence/intensity if possible.\n",
    "- Calculate total water area and percentage of valid pixels.\n",
    "- Map the water mask(s) with transparent overlays on RGB for QA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeccaa60",
   "metadata": {},
   "source": [
    "## Phase 7: Water Quality\n",
    "- Calculate a turbidity proxy such as the Normalized Difference Turbidity Index (NDTI).\n",
    "- Restrict calculations to water pixels only.\n",
    "- Create quality classes (e.g., healthy, moderate, degraded).\n",
    "- Plot maps showing turbidity gradients.\n",
    "- Note potential confounders (suspended sediment, sensor noise).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10f3df4",
   "metadata": {},
   "source": [
    "## Phase 8: Hydrological Analysis\n",
    "- Build riparian buffer zones (30 m, 100 m, 300 m) using AOI geometry.\n",
    "- Summarize NDVI or biomass statistics within each buffer to assess vegetation quality.\n",
    "- Evaluate wetland connectivity metrics (distance to water, corridor quality, area).\n",
    "- Flag priority conservation corridors based on connectivity + condition.\n",
    "- Document formulas/assumptions for reproducibility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7238ffbe",
   "metadata": {},
   "source": [
    "## Phase 9: Ecosystem Service Quantification\n",
    "- Translate biophysical metrics to per-pixel service scores for the five services.\n",
    "- **Water Flow Regulation:** estimate water storage capacity using NDVI-based vegetation factors.\n",
    "- **Water Purification:** compute pollutant removal capacity using NDVI and wetland area fractions.\n",
    "- **Sediment Control:** approximate sediment retention via simplified USLE proxies (NDVI, buffers).\n",
    "- **Aquifer Recharge:** estimate recharge potential with precipitation + NDVI-derived infiltration.\n",
    "- **Flood Protection:** approximate flood storage using floodplain extent, storage depth, roughness.\n",
    "- Produce maps and tables for each service, highlight hotspots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d17cd6e",
   "metadata": {},
   "source": [
    "## Phase 10: Dynamic Ecosystem Service Valuation\n",
    "- Assign base value coefficients ($/ha/year) to each service (per README guidance).\n",
    "- Derive Quality, Scarcity, and Benefit multipliers from indices and contextual data.\n",
    "- Compute per-pixel dynamic value = base × quality × scarcity × benefit.\n",
    "- Aggregate to total annual value and unit value (per ha) for the AOI.\n",
    "- Generate valuation maps and concise summary tables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f550f1e",
   "metadata": {},
   "source": [
    "## Phase 11: Documentation & Presentation\n",
    "- Write a clear methodology narrative covering input data, preprocessing, models, and assumptions.\n",
    "- Export publication-ready figures (maps, histograms, tables) with consistent styling.\n",
    "- Compile a concise PDF report (3–5 pages) summarizing objectives, methods, results, discussion.\n",
    "- Prepare a short slide deck (≈5 minutes) highlighting key insights and visuals.\n",
    "- Ensure notebook cells are clean, commented, and reproducible for final submission.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
